{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T10:43:44.211533Z",
     "start_time": "2020-09-04T10:43:43.913390Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T10:43:44.222645Z",
     "start_time": "2020-09-04T10:43:44.214579Z"
    }
   },
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self,data,output):\n",
    "        #data represents the feature it was split\n",
    "        #data =None for a leaf node\n",
    "        self.data=data\n",
    "        #Output represents the class with current majority at this instance\n",
    "        self.output=output\n",
    "        #children of the node is stored as a dictionary with key being the value\n",
    "        #of the feature upon which the node was split and the corresponding value stores \n",
    "        #the treenode\n",
    "        self.children={}\n",
    "        #index will be used to assign a unique index value to each node\n",
    "        self.index=-1\n",
    "        \n",
    "    def addchild(self,feature_value,obj):\n",
    "        self.children[feature_value]=obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T10:43:44.505214Z",
     "start_time": "2020-09-04T10:43:44.225489Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self):\n",
    "        self.root=None #root represents the root of the Decison Tree\n",
    "    def countunique(self,Y):\n",
    "        #returns frequency count for each class\n",
    "        freq_map={}\n",
    "        for i in Y:\n",
    "            if i not in freq_map:\n",
    "                freq_map[i]=1\n",
    "            else:\n",
    "                freq_map[i]+=1\n",
    "        return freq_map\n",
    "    def entropy(self,Y):\n",
    "        #returns the entropy\n",
    "        freq_map=self.countunique(Y)\n",
    "        total=len(Y)\n",
    "        Entropy=0\n",
    "        for i in set(Y):\n",
    "            p=freq_map[i]/total\n",
    "            Entropy+=(-p)*math.log2(p)\n",
    "        return Entropy\n",
    "    def gainratio(self,X,Y,selected_feature):\n",
    "        #returns the gain ratio\n",
    "        info_original=self.entropy(Y);\n",
    "        info_features=0\n",
    "        split_info=0\n",
    "        \n",
    "        values = set(X[:,selected_feature])\n",
    "        df=pd.DataFrame(X)\n",
    "        df[df.shape[1]]=Y\n",
    "        initialsize=df.shape[0]\n",
    "        for i in values:\n",
    "            df1=df[df[selected_feature]==i]\n",
    "            current_size=df1.shape[0]\n",
    "            info_features+=current_size/initialsize*self.entropy(df1[df1.shape[1]-1])\n",
    "            split_info+=(-(current_size/initialsize))*(math.log2(current_size/initialsize))\n",
    "        #handling for the case when split info will be 0\n",
    "        if split_info==0:\n",
    "            return math.inf\n",
    "        info_gain=info_original-info_features\n",
    "        gain_ratio=info_gain/split_info\n",
    "        return gain_ratio\n",
    "    def Decision_Tree(self,X,Y,features,level,classes):\n",
    "        #Contains PreOrder Traversal Of Tree\n",
    "        #if the node consist of only 1 class\n",
    "        # classes represents the different classes present in the classification problem \n",
    "        if len(set(Y))==1:\n",
    "            print(\"Level \",level)\n",
    "            output=None\n",
    "            for i in classes:\n",
    "                if i not in Y:\n",
    "                    print(\"Count of {} is 0\".format(i))\n",
    "                else:\n",
    "                    print(\"Count of {} is {}\".format(i,len(Y)))\n",
    "                    output=i\n",
    "            print(\"Current Entropy is 0\")\n",
    "            print(\"Reached Leaf Node\")\n",
    "            print()\n",
    "            return TreeNode(None,output)\n",
    "        #if the no. of features left is 0\n",
    "        #No feature left to predict upon, we will output the class with the \n",
    "        #max xount\n",
    "        if len(features)==0:\n",
    "            print(\"Level \",level)\n",
    "            freq_map=self.countunique(Y)\n",
    "            max_count=-math.inf\n",
    "            output=None\n",
    "            for i in classes:\n",
    "                if i not in freq_map:\n",
    "                    print(\"Count of {} is 0\".format(i))\n",
    "                else:\n",
    "                    if freq_map[i] > max_count:\n",
    "                        max_count=freq_map[i]\n",
    "                        output=i\n",
    "                    print(\"Count of {} is {}\".format(i,freq_map[i]))\n",
    "            print(\"Current Entropy is \",self.entropy(Y))\n",
    "            print(\"Reached Leaf Node\")\n",
    "            print()\n",
    "            return TreeNode(None, output)\n",
    "        #Selecting the best feature to split upon\n",
    "        print(\"Level \", level)\n",
    "        max_gain=-math.inf\n",
    "        final_feature=None\n",
    "        for f in features:\n",
    "            current_gain=self.gainratio(X,Y,f)\n",
    "            if current_gain>max_gain:\n",
    "                max_gain=current_gain\n",
    "                final_feature=f\n",
    "        freq_map=self.countunique(Y)\n",
    "        output=None\n",
    "        max_count=-math.inf\n",
    "        for i in classes:\n",
    "            if i not in freq_map:\n",
    "                print(\"Count of {} is 0\".format(i))\n",
    "            else:\n",
    "                if freq_map[i] > max_count:\n",
    "                    max_count=freq_map[i]\n",
    "                    output=i\n",
    "                print(\"Count of {} is {}\".format(i,freq_map[i]))\n",
    "        print(\"Current Entropy is {}\".format(self.entropy(Y)))\n",
    "        print(\"Spliiting on feature {} with gain ratio = {}\".format(final_feature,max_gain))\n",
    "        print()\n",
    "        current_node=TreeNode(final_feature,output)\n",
    "        unique_values=set(X[:,final_feature])\n",
    "        df=pd.DataFrame(X)\n",
    "        df[df.shape[1]]=Y\n",
    "        index=features.index(final_feature)\n",
    "        features.remove(final_feature)\n",
    "        for i in unique_values:\n",
    "            df1=df[df[final_feature]==i]\n",
    "            node=self.Decision_Tree(df1.iloc[:,0:df1.shape[1]-1].values,df1.iloc[:,df1.shape[1]-1].values,features,level+1,classes)\n",
    "            current_node.addchild(i,node)\n",
    "        features.insert(index,final_feature)\n",
    "        return current_node\n",
    "    def fit(self,X,Y):\n",
    "        #features=[i for i in range(len(X[0]))]\n",
    "        features = [i for i in range(len(X[0]))]\n",
    "        classes=set(Y)\n",
    "        self.root=self.Decision_Tree(X,Y,features,0,classes)\n",
    "    def predictfor(self,data,node):\n",
    "        #returns the class for each data point\n",
    "        \n",
    "        #we have reached a leaf node\n",
    "        if len(node.children) == 0 :\n",
    "            return node.output\n",
    "\n",
    "        val = data[node.data] \n",
    "        # represents the value of feature on which the split was made       \n",
    "        if val not in node.children :\n",
    "            return node.output\n",
    "        \n",
    "        # Recursively call on the splits\n",
    "        return self.predictfor(data,node.children[val])\n",
    "    def predict(self,X):\n",
    "        Y=np.array([0 for i in range(len(X))])\n",
    "        for i in range(len(X)):\n",
    "            Y[i]=self.predictfor(X[i],self.root)\n",
    "        return Y\n",
    "    def score(self,X,Y):\n",
    "        y_pred=self.predict(X)\n",
    "        count=0\n",
    "        for i in range(len(Y)):\n",
    "            if y_pred[i]==Y[i]:\n",
    "                count+=1\n",
    "        return count/len(Y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T10:43:44.987176Z",
     "start_time": "2020-09-04T10:43:44.507708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level  0\n",
      "Count of 0 is 50\n",
      "Count of 1 is 50\n",
      "Count of 2 is 50\n",
      "Current Entropy is 1.584962500721156\n",
      "Spliiting on feature 3 with gain ratio = 0.6996382036222091\n",
      "\n",
      "Level  1\n",
      "Count of 0 is 50\n",
      "Count of 1 is 0\n",
      "Count of 2 is 0\n",
      "Current Entropy is 0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level  1\n",
      "Count of 0 is 0\n",
      "Count of 1 is 10\n",
      "Count of 2 is 0\n",
      "Current Entropy is 0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level  1\n",
      "Count of 0 is 0\n",
      "Count of 1 is 40\n",
      "Count of 2 is 16\n",
      "Current Entropy is 0.863120568566631\n",
      "Spliiting on feature 2 with gain ratio = 0.4334099495621067\n",
      "\n",
      "Level  2\n",
      "Count of 0 is 0\n",
      "Count of 1 is 1\n",
      "Count of 2 is 0\n",
      "Current Entropy is 0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level  2\n",
      "Count of 0 is 0\n",
      "Count of 1 is 39\n",
      "Count of 2 is 8\n",
      "Current Entropy is 0.6581912658132185\n",
      "Spliiting on feature 0 with gain ratio = 0.12674503775809332\n",
      "\n",
      "Level  3\n",
      "Count of 0 is 0\n",
      "Count of 1 is 0\n",
      "Count of 2 is 1\n",
      "Current Entropy is 0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level  3\n",
      "Count of 0 is 0\n",
      "Count of 1 is 14\n",
      "Count of 2 is 0\n",
      "Current Entropy is 0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level  3\n",
      "Count of 0 is 0\n",
      "Count of 1 is 23\n",
      "Count of 2 is 7\n",
      "Current Entropy is 0.783776947484701\n",
      "Spliiting on feature 1 with gain ratio = 0.07092036405148876\n",
      "\n",
      "Level  4\n",
      "Count of 0 is 0\n",
      "Count of 1 is 3\n",
      "Count of 2 is 1\n",
      "Current Entropy is  0.8112781244591328\n",
      "Reached Leaf Node\n",
      "\n",
      "Level  4\n",
      "Count of 0 is 0\n",
      "Count of 1 is 14\n",
      "Count of 2 is 6\n",
      "Current Entropy is  0.8812908992306927\n",
      "Reached Leaf Node\n",
      "\n",
      "Level  4\n",
      "Count of 0 is 0\n",
      "Count of 1 is 6\n",
      "Count of 2 is 0\n",
      "Current Entropy is 0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level  3\n",
      "Count of 0 is 0\n",
      "Count of 1 is 2\n",
      "Count of 2 is 0\n",
      "Current Entropy is 0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level  2\n",
      "Count of 0 is 0\n",
      "Count of 1 is 0\n",
      "Count of 2 is 8\n",
      "Current Entropy is 0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level  1\n",
      "Count of 0 is 0\n",
      "Count of 1 is 0\n",
      "Count of 2 is 34\n",
      "Current Entropy is 0\n",
      "Reached Leaf Node\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "df=pd.DataFrame(iris.data)\n",
    "y=(iris.target)\n",
    "df.columns = [\"sl\", \"sw\", 'pl', 'pw']\n",
    "def label(val, *boundaries):\n",
    "    if (val < boundaries[0]):\n",
    "        return 0\n",
    "    elif (val < boundaries[1]):\n",
    "        return 1\n",
    "    elif (val < boundaries[2]):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "def toLabel(df, old_feature_name):\n",
    "    second = df[old_feature_name].mean()\n",
    "    minimum = df[old_feature_name].min()\n",
    "    first = (minimum + second)/2\n",
    "    maximum = df[old_feature_name].max()\n",
    "    third = (maximum + second)/2\n",
    "    return df[old_feature_name].apply(label, args= (first, second, third))\n",
    "df['sl_labeled'] = toLabel(df, 'sl')\n",
    "df['sw_labeled'] = toLabel(df, 'sw')\n",
    "df['pl_labeled'] = toLabel(df, 'pl')\n",
    "df['pw_labeled'] = toLabel(df, 'pw')\n",
    "df.drop(['sl', 'sw', 'pl', 'pw'], axis = 1, inplace = True)\n",
    "f=list(df.columns)\n",
    "tree=DecisionTreeClassifier()\n",
    "df=df.to_numpy()\n",
    "tree.fit(df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T10:43:44.995757Z",
     "start_time": "2020-09-04T10:43:44.989287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 2 1]\n",
      "\n",
      "My Score on Training Data 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "Y_pred = tree.predict(df)\n",
    "print(\"Predictions :\",Y_pred)\n",
    "print()\n",
    "print(\"My Score on Training Data\",tree.score(df,y)) # Score on training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T10:43:45.169561Z",
     "start_time": "2020-09-04T10:43:44.997666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(iris.data,iris.target)\n",
    "clf.score(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
